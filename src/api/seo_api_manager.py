"""
SEO APIç®¡ç†å™¨
ç®¡ç†å¤šä¸ªSEO APIæ¥å£ï¼Œç¡®ä¿ä¸¥æ ¼ä¸²è¡Œè¯·æ±‚ï¼Œé‡‡ç”¨å¹³å‡åˆ†é…ç­–ç•¥
"""

import asyncio
import aiohttp
import time
from typing import Dict, List, Optional, Any, Set
from datetime import datetime
import logging

from ..utils.log_security import LogSecurity


class SEOAPIManager:
    """SEO APIä¸²è¡Œç®¡ç†å™¨"""
    
    def __init__(self, api_urls: List[str], interval: float = 1.0,
                 batch_size: int = 5, timeout: int = 30):
        """
        åˆå§‹åŒ–SEO APIç®¡ç†å™¨ - å¢å¼ºç«¯ç‚¹ç®¡ç†

        Args:
            api_urls: APIç«¯ç‚¹URLåˆ—è¡¨
            interval: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
            batch_size: æ‰¹é‡æŸ¥è¯¢å¤§å°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.api_urls = api_urls
        self.interval = interval
        self.batch_size = batch_size
        self.timeout = timeout

        # ç«¯ç‚¹å¥åº·çŠ¶æ€è·Ÿè¸ª
        self.endpoint_health = {i: {'healthy': True, 'failures': 0, 'last_check': 0, 'requests': 0}
                               for i in range(len(api_urls))}
        self.max_failures = 3  # è¿ç»­å¤±è´¥é˜ˆå€¼
        self.health_check_interval = 300  # 5åˆ†é’Ÿé‡æ–°æ£€æŸ¥ä¸å¥åº·ç«¯ç‚¹

        # è´Ÿè½½å‡è¡¡ï¼šè½®è¯¢åˆ†é…
        self.current_endpoint_index = 0  # è½®è¯¢èµ·å§‹ç‚¹
        self.enable_load_balancing = True  # å¯ç”¨è´Ÿè½½å‡è¡¡

        # æ¯ä¸ªç«¯ç‚¹ç‹¬ç«‹çš„è¯·æ±‚é”å’Œæ—¶é—´è·Ÿè¸ª
        self.endpoint_locks = {i: asyncio.Lock() for i in range(len(api_urls))}
        self.endpoint_last_request = {i: 0 for i in range(len(api_urls))}

        self.logger = logging.getLogger(__name__)

        # è®°å½•è´Ÿè½½å‡è¡¡é…ç½®
        self.logger.info(f"ğŸ¯ è´Ÿè½½å‡è¡¡æ¨¡å¼: è½®è¯¢åˆ†é…åˆ° {len(api_urls)} ä¸ªç«¯ç‚¹")

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'api_switches': 0,
            'total_keywords_queried': 0,
            'endpoint_failures': {i: 0 for i in range(len(api_urls))}
        }

        self.logger.info(f"SEO APIç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼ŒAPIç«¯ç‚¹: {len(api_urls)}ä¸ªï¼Œè´Ÿè½½å‡è¡¡: å¹³å‡åˆ†é…")

    def _get_next_endpoint(self) -> int:
        """è½®è¯¢è·å–ä¸‹ä¸€ä¸ªå¯ç”¨ç«¯ç‚¹"""
        if not self.enable_load_balancing:
            return 0

        # å°è¯•æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¥åº·çš„ç«¯ç‚¹
        attempts = 0
        while attempts < len(self.api_urls):
            endpoint_index = self.current_endpoint_index

            # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªç«¯ç‚¹ï¼ˆè½®è¯¢ï¼‰
            self.current_endpoint_index = (self.current_endpoint_index + 1) % len(self.api_urls)

            # æ£€æŸ¥ç«¯ç‚¹æ˜¯å¦å¥åº·
            if self.endpoint_health[endpoint_index]['healthy']:
                return endpoint_index

            attempts += 1

        # å¦‚æœæ‰€æœ‰ç«¯ç‚¹éƒ½ä¸å¥åº·ï¼Œè¿”å›å¤±è´¥æ¬¡æ•°æœ€å°‘çš„
        return min(self.endpoint_health.keys(),
                  key=lambda x: self.endpoint_health[x]['failures'])

    def _mark_endpoint_failure(self, endpoint_index: int):
        """æ ‡è®°ç«¯ç‚¹å¤±è´¥"""
        import time
        health = self.endpoint_health[endpoint_index]
        health['failures'] += 1
        self.stats['endpoint_failures'][endpoint_index] += 1

        if health['failures'] >= self.max_failures:
            health['healthy'] = False
            health['last_check'] = time.time()
            self.logger.warning(f"ç«¯ç‚¹ {self.api_urls[endpoint_index]} æ ‡è®°ä¸ºä¸å¥åº· (è¿ç»­å¤±è´¥ {health['failures']} æ¬¡)")



    async def _send_request_to_endpoint(self, keywords: List[str], endpoint_index: int) -> Dict[str, Dict]:
        """å‘æŒ‡å®šç«¯ç‚¹å‘é€è¯·æ±‚"""
        if not keywords:
            return {}

        url = f"{self.api_urls[endpoint_index]}/api/keywords"
        params = {"keyword": ",".join(keywords)}

        # å®Œæ•´çš„è¶…æ—¶é…ç½®
        timeout = aiohttp.ClientTimeout(
            total=self.timeout,      # æ€»è¶…æ—¶æ—¶é—´: 30ç§’
            connect=10,              # è¿æ¥è¶…æ—¶æ—¶é—´: 10ç§’
            sock_read=15,            # è¯»å–è¶…æ—¶æ—¶é—´: 15ç§’
            sock_connect=5           # socketè¿æ¥è¶…æ—¶: 5ç§’
        )

        async with aiohttp.ClientSession(timeout=timeout) as session:
            try:
                # ç®€åŒ–æ—¥å¿—
                self.logger.debug(f"HTTPè¯·æ±‚: {url}")
                self.logger.debug(f"å…³é”®è¯: {list(keywords)}")

                async with session.get(url, params=params) as response:
                    self.logger.debug(f"HTTPå“åº”: {response.status}")
                    if response.status == 200:
                        data = await response.json()
                        # æ·»åŠ åŸå§‹å“åº”è°ƒè¯•
                        self.logger.debug(f"ğŸ” APIåŸå§‹å“åº”: {data}")
                        result = self._parse_response(data, keywords)
                        valid_count = len([r for r in result.values() if r])
                        self.logger.debug(f"ğŸ“Š è§£æç»“æœ: {valid_count}/{len(result)} ä¸ªæœ‰æ•ˆæ•°æ®")
                        return result
                    else:
                        # æ ¹æ®çŠ¶æ€ç æä¾›ç®€æ´çš„é”™è¯¯ä¿¡æ¯
                        if response.status >= 500:
                            # æœåŠ¡å™¨é”™è¯¯ï¼šåªæ˜¾ç¤ºçŠ¶æ€ç ï¼Œä¸è¾“å‡ºHTMLå†…å®¹
                            error_msg = f"{response.status}é”™è¯¯ (æœåŠ¡å™¨å†…éƒ¨é”™è¯¯)"
                            self.logger.error(f"APIé”™è¯¯å“åº”: {error_msg}")
                            raise Exception(f"APIè¿”å›é”™è¯¯çŠ¶æ€ç : {error_msg}")
                        else:
                            # å®¢æˆ·ç«¯é”™è¯¯ï¼šæ˜¾ç¤ºç®€çŸ­çš„é”™è¯¯ä¿¡æ¯
                            try:
                                error_text = await response.text()
                                # ç§»é™¤HTMLæ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬
                                import re
                                clean_text = re.sub(r'<[^>]+>', '', error_text)
                                # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
                                clean_text = ' '.join(clean_text.split())
                                clean_text = clean_text[:100]
                                if not clean_text:
                                    clean_text = f"{response.status}é”™è¯¯"
                            except:
                                clean_text = f"{response.status}é”™è¯¯"

                            self.logger.error(f"APIé”™è¯¯å“åº”: {response.status} - {clean_text}")
                            raise Exception(f"APIè¿”å›é”™è¯¯çŠ¶æ€ç : {response.status} - {clean_text}")

            except asyncio.TimeoutError:
                raise Exception(f"è¯·æ±‚è¶…æ—¶ ({self.timeout}ç§’)")
            except aiohttp.ClientError as e:
                raise Exception(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")

    async def query_keywords_serial(self, keywords: List[str]) -> Dict[str, Dict]:
        """
        è´Ÿè½½å‡è¡¡æŸ¥è¯¢å…³é”®è¯ï¼Œè½®è¯¢åˆ†é…åˆ°ä¸åŒç«¯ç‚¹

        Args:
            keywords: å…³é”®è¯åˆ—è¡¨

        Returns:
            Dict[str, Dict]: å…³é”®è¯åˆ°æ•°æ®çš„æ˜ å°„
        """
        if not keywords:
            return {}

        # å‡å°‘å†—ä½™æ—¥å¿—ï¼šåªåœ¨å¤§é‡å…³é”®è¯æ—¶æ˜¾ç¤ºINFOçº§åˆ«
        if len(keywords) > 50:
            self.logger.info(f"å¼€å§‹è´Ÿè½½å‡è¡¡æŸ¥è¯¢ {len(keywords)} ä¸ªå…³é”®è¯")
        else:
            self.logger.debug(f"å¼€å§‹è´Ÿè½½å‡è¡¡æŸ¥è¯¢ {len(keywords)} ä¸ªå…³é”®è¯")

        results = {}
        batch_count = (len(keywords) + self.batch_size - 1) // self.batch_size
        self.logger.info(f"ğŸ”„ è´Ÿè½½å‡è¡¡å¤„ç†: {batch_count} ä¸ªæ‰¹æ¬¡è½®è¯¢åˆ†é…åˆ° {len(self.api_urls)} ä¸ªç«¯ç‚¹")

        for i in range(0, len(keywords), self.batch_size):
            batch = keywords[i:i + self.batch_size]
            batch_num = i // self.batch_size + 1

            # è·å–ä¸‹ä¸€ä¸ªç«¯ç‚¹ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
            endpoint_index = self._get_next_endpoint()
            endpoint_url = self.api_urls[endpoint_index]

            self.logger.debug(f"æ‰¹æ¬¡ {batch_num}: {len(batch)} ä¸ªå…³é”®è¯ â†’ ç«¯ç‚¹ {endpoint_index} ({endpoint_url})")

            # ä½¿ç”¨è¯¥ç«¯ç‚¹çš„ç‹¬ç«‹é”
            async with self.endpoint_locks[endpoint_index]:
                # è®¡ç®—è¯¥ç«¯ç‚¹çš„ç­‰å¾…æ—¶é—´
                current_time = time.time()
                time_since_last = current_time - self.endpoint_last_request[endpoint_index]

                if time_since_last < self.interval:
                    wait_time = self.interval - time_since_last
                    self.logger.debug(f"â±ï¸ ç«¯ç‚¹ {endpoint_index} ç­‰å¾… {wait_time:.2f} ç§’")
                    await asyncio.sleep(wait_time)

                # å‘é€è¯·æ±‚
                try:
                    batch_results = await self._send_request_to_endpoint(batch, endpoint_index)
                    results.update(batch_results)

                    # æ›´æ–°è¯¥ç«¯ç‚¹çš„ç»Ÿè®¡
                    self.endpoint_last_request[endpoint_index] = time.time()
                    self.endpoint_health[endpoint_index]['requests'] += 1
                    self.endpoint_health[endpoint_index]['failures'] = 0  # é‡ç½®å¤±è´¥è®¡æ•°

                    self.stats['successful_requests'] += 1
                    self.stats['total_keywords_queried'] += len(batch)

                except Exception as e:
                    self.logger.error(f"ç«¯ç‚¹ {endpoint_index} æ‰¹æ¬¡ {batch_num} æŸ¥è¯¢å¤±è´¥: {e}")

                    # æ ‡è®°ç«¯ç‚¹å¤±è´¥
                    self._mark_endpoint_failure(endpoint_index)

                    # ä¸ºå¤±è´¥çš„å…³é”®è¯æ·»åŠ Noneç»“æœ
                    for keyword in batch:
                        results[keyword] = None
                    self.stats['failed_requests'] += 1

                self.stats['total_requests'] += 1

        # æ˜¾ç¤ºè´Ÿè½½åˆ†å¸ƒç»Ÿè®¡
        total_requests = sum(health['requests'] for health in self.endpoint_health.values())
        self.logger.info(f"è´Ÿè½½å‡è¡¡æŸ¥è¯¢å®Œæˆï¼ŒæˆåŠŸ: {len([r for r in results.values() if r])}/{len(keywords)}")
        self.logger.debug(f"è´Ÿè½½åˆ†å¸ƒ: " + ", ".join([
            f"ç«¯ç‚¹{i}({health['requests']}æ¬¡)"
            for i, health in self.endpoint_health.items()
        ]))

        return results

    async def query_keywords_streaming(self, keywords: List[str],
                                     url_keywords_map: Dict[str, Set[str]] = None,
                                     storage_callback=None,
                                     submission_callback=None) -> Dict[str, Dict]:
        """
        æµå¼æŸ¥è¯¢å…³é”®è¯ï¼Œæ”¯æŒå®æ—¶å­˜å‚¨å’Œæäº¤

        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            url_keywords_map: URLåˆ°å…³é”®è¯çš„æ˜ å°„å…³ç³»
            storage_callback: å­˜å‚¨å›è°ƒå‡½æ•° async def(keyword_data_list)
            submission_callback: æäº¤å›è°ƒå‡½æ•° async def(keyword_data_list)

        Returns:
            Dict[str, Dict]: å…³é”®è¯åˆ°æ•°æ®çš„æ˜ å°„
        """
        if not keywords:
            return {}

        self.logger.info(f"ğŸ” SEOæ•°æ®æŸ¥è¯¢: {len(keywords)} ä¸ªå…³é”®è¯")

        # æµå¼å¤„ç†ç¼“å†²åŒº
        storage_buffer = []
        submission_buffer = []
        results = {}
        processed_count = 0

        self.logger.info(f"ğŸ”„ å¼€å§‹è´Ÿè½½å‡è¡¡å¤„ç† {len(keywords)} ä¸ªå…³é”®è¯ï¼Œåˆ†ä¸º {(len(keywords) + self.batch_size - 1) // self.batch_size} ä¸ªæ‰¹æ¬¡")

        for i in range(0, len(keywords), self.batch_size):
            batch = keywords[i:i + self.batch_size]
            batch_num = i // self.batch_size + 1

            # è·å–ä¸‹ä¸€ä¸ªç«¯ç‚¹ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
            endpoint_index = self._get_next_endpoint()
            endpoint_url = self.api_urls[endpoint_index]

            # æ‰¹æ¬¡å¤„ç†æ—¥å¿—
            self.logger.debug(f"ğŸ“‹ æ‰¹æ¬¡ {batch_num}: {len(batch)} ä¸ªå…³é”®è¯ â†’ ç«¯ç‚¹ {endpoint_index} ({endpoint_url})")

            # ä½¿ç”¨è¯¥ç«¯ç‚¹çš„ç‹¬ç«‹é”å’Œæ—¶é—´è·Ÿè¸ª
            async with self.endpoint_locks[endpoint_index]:
                # è®¡ç®—è¯¥ç«¯ç‚¹çš„ç­‰å¾…æ—¶é—´
                current_time = time.time()
                time_since_last = current_time - self.endpoint_last_request[endpoint_index]

                if time_since_last < self.interval:
                    wait_time = self.interval - time_since_last
                    self.logger.debug(f"â±ï¸ ç«¯ç‚¹ {endpoint_index} ç­‰å¾… {wait_time:.2f} ç§’")
                    await asyncio.sleep(wait_time)

                # å‘é€è¯·æ±‚åˆ°æŒ‡å®šç«¯ç‚¹ï¼ˆå¹³å‡åˆ†é…ï¼Œæ— æ•…éšœè½¬ç§»ï¼‰
                batch_results = None
                try:
                    current_endpoint_url = self.api_urls[endpoint_index]
                    self.logger.debug(f"æŸ¥è¯¢æ‰¹æ¬¡ {batch_num}: {len(batch)} ä¸ªå…³é”®è¯ (ç«¯ç‚¹: {current_endpoint_url})")

                    batch_results = await self._send_request_to_endpoint(batch, endpoint_index)
                    self.logger.debug(f"æ‰¹æ¬¡æŸ¥è¯¢å®Œæˆ: æ”¶åˆ° {len(batch_results)} ä¸ªç»“æœ")

                    # æˆåŠŸæ—¶é‡ç½®å¤±è´¥è®¡æ•°å¹¶æ›´æ–°ç»Ÿè®¡
                    self.endpoint_health[endpoint_index]['failures'] = 0
                    self.endpoint_health[endpoint_index]['requests'] += 1
                    self.endpoint_last_request[endpoint_index] = time.time()

                except Exception as e:
                    self.logger.error(f"ç«¯ç‚¹ {endpoint_index} æ‰¹æ¬¡ {batch_num} æŸ¥è¯¢å¤±è´¥: {e}")

                    # æ ‡è®°ç«¯ç‚¹å¤±è´¥
                    self._mark_endpoint_failure(endpoint_index)

                    # å¹³å‡åˆ†é…æ¨¡å¼ï¼šä¸è¿›è¡Œæ•…éšœè½¬ç§»ï¼Œç›´æ¥å¤±è´¥
                    batch_results = None

                if batch_results is not None:
                    results.update(batch_results)
                    self.last_request_time = time.time()

                    # æµå¼å¤„ç†ï¼šæ”¶é›†æˆåŠŸçš„æ•°æ®
                    valid_count = 0
                    invalid_count = 0

                    for keyword, data in batch_results.items():
                        if data:  # åªå¤„ç†æˆåŠŸçš„æ•°æ®
                            processed_count += 1
                            valid_count += 1

                            keyword_data = {
                                "keyword": keyword,
                                "seo_data": data,
                                "timestamp": time.time()
                            }

                            # æ·»åŠ åˆ°ç¼“å†²åŒº
                            storage_buffer.append(keyword_data)
                            submission_buffer.append(keyword_data)

                            self.logger.debug(f"âœ… æœ‰æ•ˆæ•°æ®: {keyword} -> {data}")
                        else:
                            invalid_count += 1
                            self.logger.debug(f"ğŸ“­ æ— æœç´¢æ•°æ®: {keyword} (APIç¡®è®¤è¯¥å…³é”®è¯æ— æœç´¢é‡æ•°æ®)")

                    # æ‰¹æ¬¡ç»“æœæ—¥å¿—ï¼ˆä»…è°ƒè¯•æ¨¡å¼ï¼‰
                    self.logger.debug(f"ğŸ“Š æ‰¹æ¬¡ {batch_num} ç»“æœ: æœ‰æ•ˆ {valid_count}, æ— æ•ˆ {invalid_count}, ç¼“å†²åŒº: å­˜å‚¨{len(storage_buffer)}/æäº¤{len(submission_buffer)}")

                    # ç´¯è®¡è¿›åº¦æ—¥å¿—ï¼ˆä»…è°ƒè¯•æ¨¡å¼ï¼‰
                    if processed_count > 0 and processed_count % 100 == 0:
                        self.logger.debug(f"ğŸ“ˆ ç´¯è®¡å¤„ç† {processed_count} æ¡æœ‰æ•ˆæ•°æ®")

                    # æ¯5æ¡è§¦å‘å­˜å‚¨ (å¿«é€Ÿæµ‹è¯•)
                    if len(storage_buffer) >= 5 and storage_callback:
                        self.logger.debug(f"ğŸ’¾ è§¦å‘å­˜å‚¨: {len(storage_buffer)} æ¡æ•°æ®")
                        await storage_callback(storage_buffer.copy())
                        storage_buffer.clear()

                    # æ¯5æ¡è§¦å‘æäº¤ (å¿«é€Ÿæµ‹è¯•)
                    if len(submission_buffer) >= 5 and submission_callback:
                        self.logger.debug(f"ğŸ“¤ è§¦å‘æäº¤: {len(submission_buffer)} æ¡æ•°æ®")
                        await submission_callback(submission_buffer.copy())
                        submission_buffer.clear()

                    # æ›´æ–°ç»Ÿè®¡
                    self.stats['successful_requests'] += 1
                    self.stats['total_keywords_queried'] += len(batch)
                else:
                    # ç«¯ç‚¹å¤±è´¥ï¼Œä¸ºè¿™ä¸ªæ‰¹æ¬¡åˆ›å»ºç©ºç»“æœï¼ˆå¹³å‡åˆ†é…æ¨¡å¼ï¼šä¸é‡è¯•ï¼‰
                    for keyword in batch:
                        results[keyword] = None
                    self.logger.error(f"æ‰¹æ¬¡ {batch_num} å¤±è´¥ï¼Œæ‰€æœ‰å…³é”®è¯æ ‡è®°ä¸ºå¤±è´¥ï¼ˆå¹³å‡åˆ†é…æ¨¡å¼ï¼šä¸é‡è¯•å…¶ä»–ç«¯ç‚¹ï¼‰")
                    self.stats['failed_requests'] += 1

                self.stats['total_requests'] += 1

        # å¤„ç†å‰©ä½™ç¼“å†²åŒºæ•°æ®
        if storage_buffer and storage_callback:
            self.logger.info(f"ğŸ’¾ æœ€ç»ˆå­˜å‚¨: {len(storage_buffer)} æ¡æ•°æ®")
            await storage_callback(storage_buffer)

        if submission_buffer and submission_callback:
            self.logger.info(f"ğŸ“¤ æœ€ç»ˆæäº¤: {len(submission_buffer)} æ¡æ•°æ®")
            await submission_callback(submission_buffer)

        self.logger.info(f"æµå¼æŸ¥è¯¢å®Œæˆï¼Œå¤„ç† {processed_count} æ¡æˆåŠŸæ•°æ®ï¼Œæ€»æŸ¥è¯¢ {len(keywords)} ä¸ªå…³é”®è¯")
        return results
    

    
    def _parse_response(self, data: Any, keywords: List[str]) -> Dict[str, Dict]:
        """
        è§£æAPIå“åº”æ•°æ®

        Args:
            data: APIå“åº”æ•°æ®
            keywords: è¯·æ±‚çš„å…³é”®è¯åˆ—è¡¨

        Returns:
            Dict[str, Dict]: è§£æåçš„æ•°æ®ï¼ŒåŒ…å«çŠ¶æ€ä¿¡æ¯
        """
        results = {}

        try:
            # æ ¹æ®å®é™…APIå“åº”æ ¼å¼è§£æ
            if isinstance(data, dict) and 'data' in data and isinstance(data['data'], list):
                # å®é™…APIå“åº”æ ¼å¼: {"status": "success", "data": [{"keyword": "...", "metrics": {...}}]}

                # æ£€æŸ¥APIæ˜¯å¦ç¡®è®¤æ— æ•°æ®
                total_results = data.get('total_results', len(data['data']))
                api_status = data.get('status', 'unknown')

                self.logger.debug(f"APIå“åº”çŠ¶æ€: {api_status}, æ€»ç»“æœæ•°: {total_results}, æ•°æ®é¡¹æ•°: {len(data['data'])}")

                # å…ˆåˆå§‹åŒ–æ‰€æœ‰å…³é”®è¯ä¸ºNone
                for keyword in keywords:
                    results[keyword] = None

                # å¦‚æœAPIç¡®è®¤æ— æ•°æ®ï¼ˆtotal_results=0ä¸”dataä¸ºç©ºï¼‰
                if total_results == 0 and len(data['data']) == 0:
                    # è®°å½•APIç¡®è®¤æ— æ•°æ®çš„å…³é”®è¯
                    for keyword in keywords:
                        self.logger.debug(f"ğŸ“­ APIç¡®è®¤æ— æ•°æ®: {keyword} (total_results=0)")
                else:
                    # è§£ædataæ•°ç»„ä¸­çš„å…³é”®è¯æ•°æ®
                    for item in data['data']:
                        if isinstance(item, dict) and 'keyword' in item and 'metrics' in item:
                            keyword = item['keyword']
                            metrics = item['metrics']

                            # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨è¯·æ±‚åˆ—è¡¨ä¸­
                            if keyword in keywords:
                                if self._is_valid_keyword_data(metrics):
                                    results[keyword] = metrics
                                    self.logger.debug(f"âœ… è§£ææˆåŠŸ: {keyword}")
                                else:
                                    self.logger.debug(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {keyword} -> {metrics}")
                            else:
                                self.logger.debug(f"âš ï¸ æ„å¤–çš„å…³é”®è¯: {keyword}")

                    # æ£€æŸ¥æ˜¯å¦æœ‰å…³é”®è¯åœ¨APIå“åº”ä¸­ç¼ºå¤±ï¼ˆéƒ¨åˆ†æ— æ•°æ®ï¼‰
                    returned_keywords = {item.get('keyword') for item in data['data']
                                       if isinstance(item, dict) and 'keyword' in item}
                    for keyword in keywords:
                        if keyword not in returned_keywords and results[keyword] is None:
                            self.logger.debug(f"ğŸ“­ APIæœªè¿”å›è¯¥å…³é”®è¯: {keyword}")

            else:
                # å¦‚æœå“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œæ ‡è®°æ‰€æœ‰å…³é”®è¯ä¸ºå¤±è´¥
                self.logger.warning(f"âš ï¸ APIå“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ: {type(data)}")
                for keyword in keywords:
                    results[keyword] = None

        except Exception as e:
            self.logger.error(f"è§£æAPIå“åº”å¤±è´¥: {e}")
            # è§£æå¤±è´¥ï¼Œæ ‡è®°æ‰€æœ‰å…³é”®è¯ä¸ºå¤±è´¥
            for keyword in keywords:
                results[keyword] = None

        return results
    
    def _is_valid_keyword_data(self, data: Any) -> bool:
        """
        éªŒè¯å…³é”®è¯æ•°æ®æ˜¯å¦æœ‰æ•ˆ - æ”¾å®½éªŒè¯æ¡ä»¶

        Args:
            data: å…³é”®è¯æ•°æ®

        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        # æ”¾å®½éªŒè¯ï¼šåªè¦ä¸æ˜¯Noneä¸”æ˜¯dictå°±è®¤ä¸ºæœ‰æ•ˆ
        if data is None:
            return False

        if not isinstance(data, dict):
            return False

        # åªè¦æœ‰ä»»ä½•æ•°æ®å°±è®¤ä¸ºæœ‰æ•ˆ
        return len(data) > 0
    
    def get_current_api_url(self) -> str:
        """
        è·å–å½“å‰è½®è¯¢çš„API URLï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼‰

        Returns:
            str: å½“å‰è½®è¯¢ä½ç½®çš„API URL
        """
        return self.api_urls[self.current_endpoint_index]
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        stats = self.stats.copy()
        stats['current_endpoint_index'] = self.current_endpoint_index
        stats['current_api_url'] = self.get_current_api_url()
        stats['success_rate'] = (
            self.stats['successful_requests'] / max(self.stats['total_requests'], 1) * 100
        )
        
        return stats
    
    def reset_statistics(self) -> None:
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'api_switches': 0,
            'total_keywords_queried': 0
        }
        self.logger.info("ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    async def health_check(self) -> Dict[str, bool]:
        """
        æ£€æŸ¥æ‰€æœ‰APIç«¯ç‚¹çš„å¥åº·çŠ¶æ€
        
        Returns:
            Dict[str, bool]: API URLåˆ°å¥åº·çŠ¶æ€çš„æ˜ å°„
        """
        health_status = {}
        
        for i, api_url in enumerate(self.api_urls):
            try:
                timeout = aiohttp.ClientTimeout(total=5)  # å¥åº·æ£€æŸ¥ä½¿ç”¨è¾ƒçŸ­è¶…æ—¶
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    # å‘é€ç®€å•çš„å¥åº·æ£€æŸ¥è¯·æ±‚
                    async with session.get(f"{api_url}/health") as response:
                        health_status[api_url] = response.status == 200
            except Exception:
                health_status[api_url] = False
        
        return health_status
