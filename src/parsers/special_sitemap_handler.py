"""
ç‰¹æ®Šsitemapå¤„ç†å™¨
å¤„ç†éœ€è¦ç‰¹æ®Šé€»è¾‘çš„ç½‘ç«™sitemapï¼Œå¦‚itch.ioçš„æ¸¸æˆsitemapç´¢å¼•
"""

import asyncio
import aiohttp
import xml.etree.ElementTree as ET
from typing import Set, List, Optional
from urllib.parse import urljoin
import logging

try:
    from ..config.schemas import SpecialSitemapConfig
    from ..utils.log_security import LogSecurity
except ImportError:
    # å½“ä½œä¸ºç‹¬ç«‹æ¨¡å—è¿è¡Œæ—¶çš„å¯¼å…¥
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from config.schemas import SpecialSitemapConfig
    from utils.log_security import LogSecurity


class SpecialSitemapHandler:
    """ç‰¹æ®Šsitemapå¤„ç†å™¨"""
    
    def __init__(self, session: aiohttp.ClientSession):
        """
        åˆå§‹åŒ–ç‰¹æ®Šå¤„ç†å™¨
        
        Args:
            session: HTTPä¼šè¯å¯¹è±¡
        """
        self.session = session
        self.logger = logging.getLogger(__name__)
        
        # æ³¨å†Œå¤„ç†å™¨
        self.handlers = {
            'itch_io_games': self._handle_itch_io_games,
            'game_game_index': self._handle_game_game_index,
            'poki_index': self._handle_poki_index,
            'play_games_index': self._handle_play_games_index,
            'playgame24_index': self._handle_playgame24_index,
            'megaigry_rss': self._handle_megaigry_rss,
            'hahagames_sitemap': self._handle_hahagames_sitemap
        }
    
    async def handle_special_sitemap(self, url: str, config: SpecialSitemapConfig) -> Set[str]:
        """
        å¤„ç†ç‰¹æ®Šsitemap
        
        Args:
            url: sitemap URL
            config: ç‰¹æ®Šå¤„ç†é…ç½®
            
        Returns:
            Set[str]: æå–çš„URLé›†åˆ
        """
        handler = self.handlers.get(config.handler_type)
        if not handler:
            self.logger.error(f"æœªçŸ¥çš„å¤„ç†å™¨ç±»å‹: {config.handler_type}")
            return set()
        
        try:
            # ä½¿ç”¨å®‰å…¨æ—¥å¿—è®°å½•ï¼Œéšè—æ•æ„ŸURL
            safe_url = LogSecurity.sanitize_url(url)
            self.logger.info(f"ä½¿ç”¨ç‰¹æ®Šå¤„ç†å™¨ {config.handler_type} å¤„ç†: {LogSecurity.sanitize_url(safe_url)}")
            return await handler(url, config)
        except Exception as e:
            self.logger.error(f"ç‰¹æ®Šå¤„ç†å™¨æ‰§è¡Œå¤±è´¥ {config.handler_type}: {e}")
            return set()
    
    async def _handle_itch_io_games(self, url: str, config: SpecialSitemapConfig) -> Set[str]:
        """
        å¤„ç†itch.ioçš„æ¸¸æˆsitemapç´¢å¼•
        
        Args:
            url: itch.io sitemapç´¢å¼•URL
            config: å¤„ç†é…ç½®
            
        Returns:
            Set[str]: æ‰€æœ‰æ¸¸æˆURLé›†åˆ
        """
        # ä½¿ç”¨å®‰å…¨æ—¥å¿—è®°å½•ï¼Œéšè—æ•æ„ŸURL
        safe_url = LogSecurity.sanitize_url(url)
        self.logger.info(f"ğŸ® å¼€å§‹å¤„ç†itch.ioæ¸¸æˆsitemapç´¢å¼•: {LogSecurity.sanitize_url(safe_url)}")
        
        try:
            # 1. è·å–ä¸»sitemapç´¢å¼•
            async with self.session.get(url) as response:
                if response.status != 200:
                    self.logger.error(f"âŒ è·å–ä¸»sitemapå¤±è´¥: {response.status}")
                    return set()
                
                content = await response.text()
                self.logger.info(f"ğŸ“„ ä¸»sitemapå¤§å°: {len(content)} å­—ç¬¦")
                
                # 2. è§£æä¸»sitemapï¼Œæå–gamesç›¸å…³çš„å­sitemap
                root = ET.fromstring(content)
                
                # æŸ¥æ‰¾æ‰€æœ‰sitemapå…ƒç´ 
                sitemap_elements = (root.findall('.//sitemap') or 
                                  root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}sitemap'))
                
                self.logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(sitemap_elements)} ä¸ªå­sitemap")
                
                # 3. è¿‡æ»¤å‡ºgamesç›¸å…³çš„sitemap
                games_sitemaps = []
                for sitemap_elem in sitemap_elements:
                    loc_elem = (sitemap_elem.find('loc') or 
                              sitemap_elem.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc'))
                    
                    if loc_elem is not None and loc_elem.text:
                        sitemap_url = loc_elem.text.strip()
                        
                        # åº”ç”¨åŒ…å«å’Œæ’é™¤æ¨¡å¼
                        if self._should_include_sitemap(sitemap_url, config):
                            games_sitemaps.append(sitemap_url)
                
                self.logger.info(f"ğŸ¯ è¿‡æ»¤åçš„games sitemapæ•°é‡: {len(games_sitemaps)}")
                
                # 4. æ‰¹é‡å¤„ç†æ‰€æœ‰games sitemap
                return await self._process_games_sitemaps(games_sitemaps, config.max_concurrent)
                
        except Exception as e:
            self.logger.error(f"âŒ itch.io sitemapå¤„ç†å¤±è´¥: {e}")
            return set()
    
    async def _handle_game_game_index(self, url: str, config: SpecialSitemapConfig) -> Set[str]:
        """
        å¤„ç†game-game.comçš„sitemapç´¢å¼•
        
        Args:
            url: game-game.com sitemapç´¢å¼•URL
            config: å¤„ç†é…ç½®
            
        Returns:
            Set[str]: æ‰€æœ‰æ¸¸æˆURLé›†åˆ
        """
        # ç±»ä¼¼itch.ioçš„å¤„ç†é€»è¾‘ï¼Œä½†å¯èƒ½æœ‰ä¸åŒçš„è¿‡æ»¤è§„åˆ™
        return await self._handle_itch_io_games(url, config)
    
    async def _handle_poki_index(self, url: str, config: SpecialSitemapConfig) -> Set[str]:
        """
        å¤„ç†poki.comçš„sitemapç´¢å¼•

        Args:
            url: poki.com sitemapç´¢å¼•URL
            config: å¤„ç†é…ç½®

        Returns:
            Set[str]: æ‰€æœ‰æ¸¸æˆURLé›†åˆ
        """
        # ç±»ä¼¼çš„å¤„ç†é€»è¾‘
        return await self._handle_itch_io_games(url, config)

    async def _handle_play_games_index(self, url: str, config: SpecialSitemapConfig) -> Set[str]:
        """
        å¤„ç†play-games.comçš„sitemapç´¢å¼•

        Args:
            url: play-games.com sitemapç´¢å¼•URL
            config: å¤„ç†é…ç½®

        Returns:
            Set[str]: æ‰€æœ‰æ¸¸æˆURLé›†åˆ
        """
        # ä½¿ç”¨å®‰å…¨æ—¥å¿—è®°å½•ï¼Œéšè—æ•æ„ŸURL
        safe_url = LogSecurity.sanitize_url(url)
        self.logger.info(f"ğŸ® å¼€å§‹å¤„ç†play-games.com sitemapç´¢å¼•: {LogSecurity.sanitize_url(safe_url)}")

        try:
            # 1. è·å–ä¸»sitemapç´¢å¼•ï¼ˆæ·»åŠ User-Agenté¿å…403é”™è¯¯ï¼‰
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            async with self.session.get(url, headers=headers) as response:
                if response.status != 200:
                    self.logger.error(f"âŒ è·å–ä¸»sitemapå¤±è´¥: {response.status}")
                    return set()

                content = await response.text()
                self.logger.info(f"ğŸ“„ ä¸»sitemapå¤§å°: {len(content)} å­—ç¬¦")

                # 2. è§£æä¸»sitemapï¼Œæå–å­sitemap
                root = ET.fromstring(content)

                # æŸ¥æ‰¾æ‰€æœ‰sitemapå…ƒç´ 
                sitemap_elements = (root.findall('.//sitemap') or
                                  root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}sitemap'))

                self.logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(sitemap_elements)} ä¸ªå­sitemap")

                # 3. è¿‡æ»¤å‡ºç¬¦åˆæ¡ä»¶çš„æ¸¸æˆsitemap
                games_sitemaps = []
                import re

                # åŒ…å«æ¨¡å¼ï¼šåªè¦gamessitemap-æ•°å­—.xmlæ ¼å¼çš„è‹±æ–‡ç‰ˆæœ¬
                include_pattern = r'^https://www\.play-games\.com/sitemap/gamessitemap-\d+\.xml$'

                for sitemap_elem in sitemap_elements:
                    loc_elem = (sitemap_elem.find('loc') or
                              sitemap_elem.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc'))

                    if loc_elem is not None and loc_elem.text:
                        sitemap_url = loc_elem.text.strip()

                        # æ£€æŸ¥æ˜¯å¦åŒ¹é…åŒ…å«æ¨¡å¼
                        if re.match(include_pattern, sitemap_url):
                            # è¿›ä¸€æ­¥æ£€æŸ¥æ’é™¤æ¨¡å¼ï¼ˆç¡®ä¿æ²¡æœ‰è¯­è¨€ä»£ç ï¼‰
                            if self._should_include_sitemap(sitemap_url, config):
                                games_sitemaps.append(sitemap_url)
                                # ä½¿ç”¨å®‰å…¨æ—¥å¿—è®°å½•ï¼Œéšè—æ•æ„ŸURL
                                safe_sitemap_url = LogSecurity.sanitize_url(sitemap_url)
                                self.logger.debug(f"âœ… åŒ…å«sitemap: {LogSecurity.sanitize_url(LogSecurity.sanitize_url(safe_sitemap_url))}")
                            else:
                                # ä½¿ç”¨å®‰å…¨æ—¥å¿—è®°å½•ï¼Œéšè—æ•æ„ŸURL
                                safe_sitemap_url = LogSecurity.sanitize_url(sitemap_url)
                                self.logger.debug(f"âŒ æ’é™¤sitemap: {LogSecurity.sanitize_url(LogSecurity.sanitize_url(safe_sitemap_url))}")
                        else:
                            # ä½¿ç”¨å®‰å…¨æ—¥å¿—è®°å½•ï¼Œéšè—æ•æ„ŸURL
                            safe_sitemap_url = LogSecurity.sanitize_url(sitemap_url)
                            self.logger.debug(f"ğŸ” ä¸åŒ¹é…æ¨¡å¼: {LogSecurity.sanitize_url(LogSecurity.sanitize_url(safe_sitemap_url))}")

                self.logger.info(f"ğŸ¯ è¿‡æ»¤åçš„æ¸¸æˆsitemapæ•°é‡: {len(games_sitemaps)}")

                # æ˜¾ç¤ºå‰å‡ ä¸ªç¬¦åˆæ¡ä»¶çš„sitemap
                if games_sitemaps:
                    self.logger.info("ğŸ“‹ ç¬¦åˆæ¡ä»¶çš„sitemapç¤ºä¾‹:")
                    for i, sitemap_url in enumerate(games_sitemaps[:5]):
                        self.logger.info(f"  {i+1}. {LogSecurity.sanitize_url(LogSecurity.sanitize_url(sitemap_url))}")

                # 4. æ‰¹é‡å¤„ç†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„æ¸¸æˆsitemap
                if games_sitemaps:
                    return await self._process_games_sitemaps(games_sitemaps, config.max_concurrent)
                else:
                    self.logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¸¸æˆsitemap")
                    return set()

        except Exception as e:
            self.logger.error(f"âŒ play-games.com sitemapå¤„ç†å¤±è´¥: {e}")
            return set()

    async def _handle_playgame24_index(self, url: str, config: SpecialSitemapConfig) -> Set[str]:
        """
        å¤„ç†playgame24.comçš„sitemapç´¢å¼•
        åªæå–ç‰¹å®šçš„ä¸¤ä¸ªå­sitemap

        Args:
            url: playgame24.com sitemapç´¢å¼•URL
            config: å¤„ç†é…ç½®

        Returns:
            Set[str]: æ‰€æœ‰æ¸¸æˆURLé›†åˆ
        """
        self.logger.info(f"ğŸ® å¼€å§‹å¤„ç†playgame24.com sitemapç´¢å¼•: {LogSecurity.sanitize_url(url)}")

        try:
            # 1. è·å–ä¸»sitemapç´¢å¼•
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            async with self.session.get(url, headers=headers) as response:
                if response.status != 200:
                    self.logger.error(f"âŒ è·å–ä¸»sitemapå¤±è´¥: {response.status}")
                    return set()

                content = await response.text()
                self.logger.info(f"ğŸ“„ ä¸»sitemapå¤§å°: {len(content)} å­—ç¬¦")

                # 2. è§£æä¸»sitemapï¼ŒæŸ¥æ‰¾ç‰¹å®šçš„å­sitemap
                root = ET.fromstring(content)

                # æŸ¥æ‰¾æ‰€æœ‰sitemapå…ƒç´ 
                sitemap_elements = (root.findall('.//sitemap') or
                                  root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}sitemap'))

                self.logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(sitemap_elements)} ä¸ªå­sitemap")

                # 3. æŸ¥æ‰¾ç‰¹å®šçš„ä¸¤ä¸ªå­sitemap
                target_sitemaps = [
                    "https://playgame24.com/sitemaps/sitemap_0_ru.xml",
                    "https://playgame24.com/sitemaps/sitemap_online_0_ru.xml"
                ]

                found_sitemaps = []

                for sitemap_elem in sitemap_elements:
                    loc_elem = (sitemap_elem.find('loc') or
                              sitemap_elem.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc'))

                    if loc_elem is not None and loc_elem.text:
                        sitemap_url = loc_elem.text.strip()

                        # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬è¦çš„ç‰¹å®šsitemap
                        if sitemap_url in target_sitemaps:
                            found_sitemaps.append(sitemap_url)
                            self.logger.info(f"âœ… æ‰¾åˆ°ç›®æ ‡sitemap: {LogSecurity.sanitize_url(LogSecurity.sanitize_url(sitemap_url))}")
                        else:
                            self.logger.debug(f"ğŸ” è·³è¿‡sitemap: {LogSecurity.sanitize_url(LogSecurity.sanitize_url(sitemap_url))}")

                self.logger.info(f"ğŸ¯ æ‰¾åˆ°çš„ç›®æ ‡sitemapæ•°é‡: {len(found_sitemaps)}")

                # éªŒè¯æ˜¯å¦æ‰¾åˆ°äº†æ‰€æœ‰ç›®æ ‡sitemap
                missing_sitemaps = set(target_sitemaps) - set(found_sitemaps)
                if missing_sitemaps:
                    self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°çš„ç›®æ ‡sitemap: {list(missing_sitemaps)}")

                # 4. æ‰¹é‡å¤„ç†æ‰¾åˆ°çš„ç›®æ ‡sitemap
                if found_sitemaps:
                    return await self._process_games_sitemaps(found_sitemaps, config.max_concurrent)
                else:
                    self.logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç›®æ ‡sitemap")
                    return set()

        except Exception as e:
            self.logger.error(f"âŒ playgame24.com sitemapå¤„ç†å¤±è´¥: {e}")
            return set()

    async def _handle_megaigry_rss(self, url: str, config: SpecialSitemapConfig) -> Set[str]:
        """
        å¤„ç†megaigry.ruçš„RSS feed

        Args:
            url: RSS feed URL
            config: å¤„ç†é…ç½®

        Returns:
            Set[str]: æå–çš„æ¸¸æˆURLé›†åˆ
        """
        self.logger.info(f"ğŸ“¡ å¼€å§‹å¤„ç†megaigry.ru RSS feed: {LogSecurity.sanitize_url(url)}")

        try:
            # 1. è·å–RSS feedå†…å®¹
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'application/rss+xml, application/xml, text/xml, */*',
                'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8'
            }

            async with self.session.get(url, headers=headers) as response:
                if response.status != 200:
                    self.logger.error(f"âŒ è·å–RSS feedå¤±è´¥: {response.status}")
                    return set()

                content = await response.text()
                self.logger.info(f"ğŸ“„ RSS feedå¤§å°: {len(content)} å­—ç¬¦")

                # 2. è§£æRSS feed
                import xml.etree.ElementTree as ET
                root = ET.fromstring(content)

                # æŸ¥æ‰¾æ‰€æœ‰itemå…ƒç´ 
                items = root.findall('.//item')
                self.logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(items)} ä¸ªRSSæ¡ç›®")

                # 3. æå–æ¸¸æˆURL
                game_urls = set()
                for item in items:
                    # å°è¯•ä»linkæˆ–guidå…ƒç´ è·å–URL
                    link_elem = item.find('link') or item.find('guid')
                    if link_elem is not None and link_elem.text:
                        url_text = link_elem.text.strip()
                        # åªåŒ…å«æ¸¸æˆé¡µé¢URL
                        if '/online-game/' in url_text:
                            game_urls.add(url_text)

                self.logger.info(f"âœ… ä»RSS feedæå– {LogSecurity.sanitize_url(LogSecurity.sanitize_url(len(game_urls)))} ä¸ªæ¸¸æˆURL")

                # æ˜¾ç¤ºå‰å‡ ä¸ªURLä½œä¸ºéªŒè¯
                if game_urls:
                    self.logger.info("ğŸ“‹ æå–çš„æ¸¸æˆURLç¤ºä¾‹:")
                    for i, game_url in enumerate(list(game_urls)[:5]):
                        self.logger.info(f"  {i+1}. {LogSecurity.sanitize_url(LogSecurity.sanitize_url(game_url))}")

                return game_urls

        except Exception as e:
            self.logger.error(f"âŒ megaigry.ru RSSå¤„ç†å¤±è´¥: {e}")
            return set()

    async def _handle_hahagames_sitemap(self, url: str, config: SpecialSitemapConfig) -> Set[str]:
        """
        å¤„ç†hahagames.comçš„sitemapï¼Œä½¿ç”¨ç‰¹æ®Šçš„è¯·æ±‚å¤´é¿å…403é”™è¯¯

        Args:
            url: sitemap URL
            config: å¤„ç†é…ç½®

        Returns:
            Set[str]: æå–çš„æ¸¸æˆURLé›†åˆ
        """
        self.logger.info(f"ğŸ® å¼€å§‹å¤„ç†hahagames.com sitemap: {LogSecurity.sanitize_url(url)}")

        try:
            # 1. ä½¿ç”¨ç‰¹æ®Šçš„è¯·æ±‚å¤´é¿å…403é”™è¯¯
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Cache-Control': 'max-age=0'
            }

            async with self.session.get(url, headers=headers) as response:
                if response.status != 200:
                    self.logger.error(f"âŒ è·å–sitemapå¤±è´¥: {response.status}")
                    return set()

                content = await response.text()
                self.logger.info(f"ğŸ“„ sitemapå¤§å°: {len(content)} å­—ç¬¦")

                # 2. è§£æsitemap XML
                import xml.etree.ElementTree as ET
                root = ET.fromstring(content)

                # æŸ¥æ‰¾æ‰€æœ‰URLå…ƒç´ 
                url_elements = (root.findall('.//url') or
                              root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}url'))

                self.logger.info(f"ğŸ“‹ æ‰¾åˆ° {LogSecurity.sanitize_url(len(url_elements))} ä¸ªURLå…ƒç´ ")

                # 3. æå–æ¸¸æˆç›¸å…³çš„URL
                game_urls = set()
                for url_elem in url_elements:
                    # æŸ¥æ‰¾locå…ƒç´ 
                    loc_elem = (url_elem.find('loc') or
                              url_elem.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc'))

                    if loc_elem is not None and loc_elem.text:
                        url_text = loc_elem.text.strip()

                        # è¿‡æ»¤æ¸¸æˆç›¸å…³çš„URLï¼Œæ’é™¤è¯­è¨€é¦–é¡µå’Œå…¶ä»–éæ¸¸æˆé¡µé¢
                        if self._is_hahagames_game_url(url_text):
                            game_urls.add(url_text)

                self.logger.info(f"âœ… ä»sitemapæå– {LogSecurity.sanitize_url(LogSecurity.sanitize_url(len(game_urls)))} ä¸ªæ¸¸æˆURL")

                # æ˜¾ç¤ºå‰å‡ ä¸ªURLä½œä¸ºéªŒè¯
                if game_urls:
                    self.logger.info("ğŸ“‹ æå–çš„æ¸¸æˆURLç¤ºä¾‹:")
                    for i, game_url in enumerate(list(game_urls)[:5]):
                        self.logger.info(f"  {i+1}. {LogSecurity.sanitize_url(LogSecurity.sanitize_url(game_url))}")

                return game_urls

        except Exception as e:
            self.logger.error(f"âŒ hahagames.com sitemapå¤„ç†å¤±è´¥: {e}")
            return set()

    def _is_hahagames_game_url(self, url: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºhahagames.comçš„æ¸¸æˆURL

        Args:
            url: è¦æ£€æŸ¥çš„URL

        Returns:
            bool: æ˜¯å¦ä¸ºæ¸¸æˆURL
        """
        # æ’é™¤è¯­è¨€é¦–é¡µå’Œå…¶ä»–éæ¸¸æˆé¡µé¢
        exclude_patterns = [
            r'^https://www\.hahagames\.com/$',  # ä¸»é¡µ
            r'^https://www\.hahagames\.com/[a-z]{2}$',  # è¯­è¨€é¦–é¡µ (å¦‚ /es, /pt, /de)
            r'^https://www\.hahagames\.com/[a-z]{2}/$',  # è¯­è¨€é¦–é¡µå¸¦æ–œæ 
            r'.*/category/.*',  # åˆ†ç±»é¡µé¢
            r'.*/tag/.*',       # æ ‡ç­¾é¡µé¢
            r'.*/search.*',     # æœç´¢é¡µé¢
            r'.*/about.*',      # å…³äºé¡µé¢
            r'.*/contact.*',    # è”ç³»é¡µé¢
            r'.*/privacy.*',    # éšç§é¡µé¢
            r'.*/terms.*',      # æ¡æ¬¾é¡µé¢
            r'.*/sitemap.*',    # sitemapé¡µé¢
            r'.*/robots.*',     # robotsé¡µé¢
        ]

        import re
        for pattern in exclude_patterns:
            if re.match(pattern, url):
                return False

        # åŒ…å«æ¸¸æˆç›¸å…³çš„URLæ¨¡å¼
        include_patterns = [
            r'.*/game/.*',      # æ¸¸æˆé¡µé¢
            r'.*/games/.*',     # æ¸¸æˆåˆ—è¡¨é¡µé¢
            r'.*-game$',        # ä»¥-gameç»“å°¾çš„URL
            r'.*-games$',       # ä»¥-gamesç»“å°¾çš„URL
        ]

        for pattern in include_patterns:
            if re.search(pattern, url):
                return True

        # å¦‚æœURLåŒ…å«æ¸¸æˆç›¸å…³å…³é”®è¯ï¼Œä¹Ÿè®¤ä¸ºæ˜¯æ¸¸æˆURL
        game_keywords = ['play', 'puzzle', 'action', 'adventure', 'racing', 'sports', 'strategy']
        url_lower = url.lower()
        for keyword in game_keywords:
            if keyword in url_lower:
                return True

        return False

    def _should_include_sitemap(self, sitemap_url: str, config: SpecialSitemapConfig) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥åŒ…å«æŸä¸ªsitemap
        
        Args:
            sitemap_url: sitemap URL
            config: å¤„ç†é…ç½®
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥åŒ…å«
        """
        import re
        
        # æ£€æŸ¥åŒ…å«æ¨¡å¼
        if config.include_patterns:
            included = False
            for pattern in config.include_patterns:
                if re.search(pattern, sitemap_url):
                    included = True
                    break
            if not included:
                return False
        
        # æ£€æŸ¥æ’é™¤æ¨¡å¼
        for pattern in config.exclude_patterns:
            if re.search(pattern, sitemap_url):
                return False
        
        return True
    
    async def _process_games_sitemaps(self, sitemap_urls: List[str], max_concurrent: int) -> Set[str]:
        """
        å¹¶å‘å¤„ç†å¤šä¸ªgames sitemap
        
        Args:
            sitemap_urls: sitemap URLåˆ—è¡¨
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            
        Returns:
            Set[str]: æ‰€æœ‰æ¸¸æˆURLé›†åˆ
        """
        all_game_urls = set()
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_single_sitemap(sitemap_url: str) -> Set[str]:
            async with semaphore:
                try:
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                    }
                    async with self.session.get(sitemap_url, headers=headers) as response:
                        if response.status == 200:
                            content = await response.text()
                            root = ET.fromstring(content)
                            
                            # æå–URL
                            url_elements = (root.findall('.//url') or 
                                          root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}url'))
                            
                            urls = set()
                            for url_elem in url_elements:
                                loc_elem = (url_elem.find('loc') or 
                                          url_elem.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc'))
                                if loc_elem is not None and loc_elem.text:
                                    urls.add(loc_elem.text.strip())
                            
                            self.logger.debug(f"âœ… ä» {LogSecurity.sanitize_url(LogSecurity.sanitize_url(sitemap_url))} æå– {len(urls)} ä¸ªURL")
                            return urls
                        else:
                            self.logger.warning(f"âŒ è·å–sitemapå¤±è´¥ {LogSecurity.sanitize_url(LogSecurity.sanitize_url(sitemap_url))}: {response.status}")
                            return set()
                            
                except Exception as e:
                    self.logger.error(f"âŒ å¤„ç†sitemapå¤±è´¥ {LogSecurity.sanitize_url(LogSecurity.sanitize_url(sitemap_url))}: {e}")
                    return set()
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = [process_single_sitemap(url) for url in sitemap_urls]
        
        # æ‰§è¡Œä»»åŠ¡å¹¶æ”¶é›†ç»“æœ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        processed_count = 0
        failed_count = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                failed_count += 1
                self.logger.error(f"ä»»åŠ¡å¤±è´¥ {LogSecurity.sanitize_url(LogSecurity.sanitize_url(sitemap_urls[i]))}: {result}")
            else:
                processed_count += 1
                all_game_urls.update(result)
        
        self.logger.info(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {processed_count}, å¤±è´¥ {failed_count}, æ€»URL {LogSecurity.sanitize_url(LogSecurity.sanitize_url(len(all_game_urls)))}")
        
        return all_game_urls
